# 5. 클러스터 관리(Cluster Maintenance)

## OS 업그레이드(OS Upgrade)

+ SW 업그레이드 or security patch 등 노드를 내려야하는 경우

  + 노드가 `pod-eviction-timeout`(default : 5분) 안에 정상화되지 않으면 → pod 종료됨

    + `kube-controller-manager --pod-eviction-timeout=5m0s ...`

  + 단 5분 내로 노드가 복구되면 (kubelet에 의해) 해당 pod도 다시 뜸

  + replicaset의 pod의 경우 → 다른 노드에서 재생성됨 / 일반 pod일 경우 → 사라짐

    <img src="https://user-images.githubusercontent.com/33214969/161427053-e12a3ea7-7f23-4c98-824b-6cb43d9bceff.png" alt="OS 업데이트 - pod 종료-1.png" width="50%;" />

    <img src="https://user-images.githubusercontent.com/33214969/161427054-d9d79e33-6813-41c9-9edc-6d6cd1a6ac4c.png" alt="OS 업데이트 - pod 종료-2.png" width="50%;" />

### Drain 명령어

```tex
▫️ 해당 노드는 스케줄링에서 제외(unschedulable) + 해당 노드에 떠있는 pod들을 종료하고 다른 노드에 띄움
```

+ 이때 이동되는 pod들은 replicaset에 의해 생성된 pod 뿐만 아니라 모든 pod들이 해당됨

+ 노드/pod를 내려야 하는 경우에 사용함

  <img src="https://user-images.githubusercontent.com/33214969/161427051-e831a101-acc6-4d01-b8cd-1d4fc2e556bd.png" alt="OS 업데이트 - drain.png" width="50%;" />

+ drain 후 노드의 상태 : Ready, SchedulingDisabled

+ drain vs cordon

  + drain : 해당 노드를 스케줄링에서 제외 + 해당 노드에 떠있는 pod들을 종료하고 다른 노드에 띄움
  + cordon : 해당 노드를 스케줄링에서 제외 + 현재 떠있는 pod에 영향 없음 → 이후에 새롭게 생성되는 pod들이 이 노드에 스케줄링되지 X

### Uncordon 명령어

```tex
▫️ 노드 복구
```

+ 노드 작업이 끝난 후 `uncordon` 명령어를 통해 해당 노드를 클러스터로 복귀시킴 → 단 pod들은 되돌아오지 않음

  <img src="https://user-images.githubusercontent.com/33214969/161427045-de550830-6658-428e-8d21-10c25db7d844.png" alt="OS 업데이트 - 노드 업데이트.png" width="30%;" />

+ 관련 명령어

  + drain : 

    ```
    kubectl drain [node명]
    ```

    + (옵션) local data 모두 삭제 : `--delete-local-data`
    + (옵션) demonset을 무시하고 모두 삭제 : `--ignore-daemonsets`

  + uncordon : `kubectl uncordon [node명]`

<br/>

## 쿠버네티스 버전(Kubernetes Versions)

```tex
▫️ v[MACJOR].[MINOR].[PATCH]
```

<img src="https://user-images.githubusercontent.com/33214969/161427268-f49e83ea-d28a-4cec-9791-7bd91a404fec.png" alt="쿠버네티스 버전.png" width="30%;" />

+ ETCD, CoreDNS → 따로 독립된 버전으로 개발됨

+ 쿠버네티스의 모든 구성요소가 같은 버전일 필요 X

+ kube-apiserver는 control plane의 핵심 요소로, 다른 구성요소보다 버전이 항상 높아야 함

  + kube-apiserver > Controller-manager, kube-scheduler > kubelet, kube-proxy 순서

  + kubectl은 `x+1 ~ x-1`까지 가능함

    <img src="https://user-images.githubusercontent.com/33214969/161427291-6ba16152-5fdf-404c-9625-d989b17cc089.png" alt="쿠버네티스 버전4.png" width="30%;" />

+ 쿠버네티스는 새 버전이 릴리즈 되었을 때, 두 버전 이전 까지만 지원됨 → 이에 맞춰 업그레이드 필요함

  + ex) new version : v1.13 → v1.12, v1.11까지 지원됨
  + 업그레이드 시, minor 버전을 하나씩 올리는 것을 추천함

+ 배포 버전

  + alpha : 추가되는 기능들을 disable한 현태로 배포
  + beta : 추가 기능들을 enable한 형태로 배포
  + release : 안정화된 버전을 배포

<br/>

## 클러스터 업그레이드(Cluster Upgrade)

+ Master Node > Worker Node 업그레이드 순서로 진행

### Master Node 업그레이드

+ 마스터 노드가 업그레이드 되는 동안 → apiserver, scheduler, controller manager 등 control plane 구성 요소들이 다운됨
+ 단, worker node or pod(애플리케이션)에 영향 X

### Worker Node 업그레이드

+ Worker node 업그레이드 방법 3가지

  1. 한 번에 모두 업그레이드
     + 애플리케이션 접근 불가
  2. 하나씩 업그레이드
     + 노드 1개씩 업그레이드할 노드의 pod들을 옮김 + 업그레이드 후 다시 옮김
     + downtime X
  3. 새 노드 추가 + 원래 노드를 evict
     + 클라우드 환경에서 편리하게 가능함

+ 관련 명령어

  + 업그레이드 시, 관련 정보 : `kubeadm upgrade plan`

  1. kubeadm 버전 업그레이드 : `apt update` + `apt install -y kubeadm=1.18.0-00` / `api-get upgrade -y kubeadm=1.18.0-00`
  2. 클러스터(컴포넌트) 업그레이드 : `kubeadm upgrade apply v1.18.0`
  3. 노드 버전 체크 : `kubectl get nodes`

  → 여기까지 진행 시, 클러스터의 버전이 변경되지 X → apiserver 버전이 아닌 apiserver에 등록된 kubelet의 버전을 업그레이드 했기 때문

  4. Master Node의 kubelet 업그레이드 : `apt install kubelet=1.18.0-00` / `api-get upgrade -y kubelet=1.18.0-00` + `systemctl restart kubelet`
  5. Worker Node 업그레이드
     1. Worker Node 하나씩 접속 : `ssh [node명]`
     2. 노드 이동 : `kubectl drain [node명] (--ignore-daemonsets)`
     3. 노드를 unschedulable 상태로 변경 : `kubectl cordon [node명]`
     4. kubeadm 업그레이드 : `apt update` +  `apt install -y kubeadm=1.18.0-00` / `api-get upgrade -y kubeadm=1.18.0-00` + `kubeadm upgrade node`
     5. kubelet 업그레이드 : `apt install kubelet=1.18.0-00` / `api-get upgrade -y kubelet=1.18.0-00`
     6. 새로운 버전 설정 : `kubeadm upgrade node config --kubelet-version v1.18.0`
     7. kubelet 재시작 : `systemctl restart kubelet`
     8. 노드 uncordeon : `kubectl uncordon [node명]`

  * Worker Node 업그레이드(요약)
    1. `ssh [node명]`
    2. `apt update`
    3. `apt install kubeadm=1.18.0-00`
    4. `kubeadm upgrade node`
    5. `apt install kubelet=1.18.0-00`
    6. `systemctl restart kubelet`
    7. `exit` or `CTL+d`

<br/>

## 백업(Backup) & 복구(Restore)

### Backup

+ 백업 대상 - 각종 오브젝트, ETCD 클러스터, Persisten Volume

+ declarative 방식(파일로 object를 생성하는 방식)이 백업하는데 선호됨

+ 리소스 백업 방법 → 오브젝트 설정 정보 저장(pod, deployment, service만 가능함)

  `kubectl get all -A -o yaml > [yaml 파일명].yaml`

+ ETCD 스냅샷

  + 스냅샷 생성 : `ETCDTL_API=3 etcdctl snapshot save [snapshot명].db`

    ```bash
    $ ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 \\
    --cacert=/etc/kubernetes/pki/etcd/ca.crt \\
    --cert=/etc/kubernetes/pki/etcd/server.crt \\
    --key=/etc/kubernetes/pki/etcd/server.key \\
    snapshot save /opt/snapshot-pre-boot.db
    ```

  + 스냅샷 상태 확인 : `ETCDTL_API=3 etcdctl snapshot status snapshot.db`

+ ETCD 백업

  ```bash
  $ sudo ETCDCTL_API=3 ./etcdctl \\\\
  	--endpoints 127.0.0.1:2379 \\\\
  	--cacert /etc/kubernetes/pki/etcd/ca.crt \\\\
  	--cert /etc/kubernetes/pki/etcd/server.crt \\\\
  	--key /etc/kubernetes/pki/etcd/server.key \\\\
  	snapshot save snapshotdb
  ```

  + 위 옵션 → etcd 프로세스에서 확인 가능

    + ```
      ps -aux | grep -i etcd
      ```

      + `--cert-file` / `--key-file` / `--trusted-ca-file`

### Restore

+ ETCD Restore

  1. kube-apiserver 중지 : `service kube-apiserver stop`

  2. etcd restore → etcd config 파일에 `--data-dir`이  적용되어 있음 : `ETCDCTL_API=3 etcdctl snapshot restore snapshot.db --data-dir /var/lib/etcd-from-backup`

  3. `systemctl daemon-reload`

  4. `service etcd restart`

  5. `service kube-apiserver start`

  6. ETCD pod는 static pod임 → `/etc/kubernetes/manifests/etcd.yaml` 파일이 존재함

  7. 해당 yaml 파일에서 restore할 때, 자신이 지정한 —data-dir /var/lib/etcd-from-backup으로 수정해야 함

     ```yaml
     volumes:
     - hostPath:
         path: /etc/kubernetes/pki/etcd
     	    type: DirectoryOrCreate
       name: etcd-certs
     - hostPath:
         path: /var/lib/etcd-from-backup    # 여기를 수정!
         type: DirectoryOrCreate
       name: etcd-data
     ```

  8. 수정 후 저장 > 쿠버네티스가 ETCD pod를 재생성 + data 디렉토리를 `/var/lib/etcd-from-backup`을 바라봄

<br/><br/>