# 7. 스토리지(Storage)

## Docker Storage

### Storage Drivers

+ File system → /var/lib/docker/containers,image,volumes 에 default로 도커 데이터를 저장함
+ Volume Mount : `docker volume create date_volume` → /var/lib/docker/volumes/data_volume에 volume이 생성됨
+ volume을 도커 컨테이너 내에 mount : `docker run -v data_volume:/var/lib/mysql mysql` → mysql 컨테이너 내에 /var/llib/mysql 폴더로 마운트됨 → `-v` 옵션 :  `docker run`할 때 volume을 생성하지 않아도 해당 이름의 volume이 자동으로 생성됨
+ Bind Mount : `docker run -v /data/mysql:/var/lib/mysql mysql` / `docker run --mount type=bind, source=/data/mysql, target=/var/lib/mysql mysql` → Host에 존재하는 폴더를 컨테이너 내부로 mount
+ Storage driver의 역할 - 도커의 operation, layered 구조 유지, writable layer 생성, ...
+ ex) AUFS, ZFS, BTRFS, Device Mapper Overlay, Overlay2, ...

### Volume Driver

+ Volume Driver의 역할 - volume을 다룸
+ 기본적인 volume plugin : local volume plugin
  + local volume plugin이 host에 volume을 생성 + 데이터를 저장
  + 그 외 3rd party volume driver를 사용해도 됨 ex) Azure File Storage, Convoy, Digital Ocean Block, ...
+ driver 지정 : `docker run --volume-driver`

### Container Storage Interface

+ CRI(Container Runtime Interface) : 쿠버네티스 같은 솔루션이 도커와 같은 container runtime 솔루션과 소통하는지 정의하는 기준
+ CNI(Container Network Interface) : 네트워크 인터페이스로 CNI를 지킴으로써 쿠버네티스와 작동할 수 있는 네트워크 플러그인을 개발할 수 있음
+ CSI(Container Storage Interface) : 여러 storage 솔루션을 위한 인터페이스

<br/>

## Volumes

```tex
▫️ pod에 종속되는 디스크(=컨테이너의 외장디스크)
```

### Volume in Docker

+ 도커 컨테이너는 데이터 처리가 필요할 때 요청 + 처리 완료 후에는 삭제됨 → 이때, 컨테이너 내의 데이터도 함께 삭제됨 → 이 데이터들을 유지하기 위해서 volume을 설정하여 사용
+ volume을 설정 → 컨테이너에서 처리한 데이터가 volume에 저장됨 ⇒ 컨테이너 삭제 후에도 데이터 유지 가능함

### Volume in Kubernetes

<img src="https://user-images.githubusercontent.com/33214969/161439916-43a7b18b-0795-42b5-bf05-0acbffdb9160.png" alt="Storage - Volume.png" width="30%;" />

+ 쿠버네티스 pod 역시 데이터 처리한 뒤 삭제됨 → 이때 처리한 데이터도 함께 삭제됨

+ volume을 설정 → pod에서 처리한 데이터가 volume에 저장됨 ⇒ pod 삭제 후에도 데이터 유지 가능함

+ Volume 구성 방법

  + Host Path

    + Host 디렉토리를 사용하는 방법 → volume 내에서 생성된 파일이 Host 디렉토리에 저장됨

    + volume 생성 후 컨테이너에서 볼륨을 접근할 수 있도록 컨테이너 내의 디렉토리에 마운트(volumeMount)를 해야 함

    + yaml 파일

      ```yaml
      apiVersion: v1
      kind: Pod
      metadata:
        name: random-number-generator
      spec:
        containers:
        - image: alpine
          name: alpine
          command: ["/bin/sh", "-c"]
          args: ["shuf -i 0-100 -n 1 >> /opt/number.out;"]
          volumeMounts:  # volume을 mount
          - mountPath: /opt  # volume mount : volume 생성 path
            name: data-volume
        volumes:
        - name: data-volume
          hostPath:
            path: /data    # volume host path
            type: Directory
      ```

  + 외부 클러스터 스토리지 솔루션

    + 스토리지 솔루션 : NFS, glusterFS, Flocker, FibreChannel, ...

    + 클러스터 솔루션 : AWS EBS, Azure Disk, Azure File, Google’s Persistent Disk

      + ex) AWS EBS

        ```yaml
        ...
          volumes:
          - name: data-volume
            awsElasticBlockStore:
              volumeID: [volume id]
              fsType: ext4
        ...
        ```

<br/>

## 퍼시스턴트 볼륨(PV, Persistent Volumes)

```tex
▫️ 관리자에 의해 생성된 클러스터 전체의 storage volume pool
```

<img src="https://user-images.githubusercontent.com/33214969/161439900-cbc82b5e-67f2-46eb-86a3-8f47eaa4c4d1.png" alt="Storage - PV.png" width="50%;" />

+ 특징

  + Storage 중앙 관리용
  + 클러스터에서 애플리케이션을 배포하는 사용자가 사용함
  + 사용자는 PVC(Persistent Volumes Claims)를 사용하여 pool에서 storage를 선택함

+ PV 생성 방법(yaml 파일)

  + accessModes : host에서 volume을 마운트하는 방법 ex) ReadWriteOnce | ReadOnlyMany | ReadWriteMany
  + capacity : storage 용량 설정
  + hostPath : volume 유형

  + 단, AWS EBS 사용 시, `awsElasticBlockStore`으로 대체해야 함

  ```yaml
  # pv-definition.yaml
  apiVersion: v1
  kind: PersistentVolume
  metadata:
    name: pv-vol1
  spec:
    accessModes:
      - ReadWriteOnce  # ReadWriteOnce|ReadOnlyMany|ReadWriteMany
    capacity:    # 예약할 storage 용량
      storage: 1Gi
    hostPath:
      path: /tmp/data
    gcePersistentDisk:
      pdName: pd-disk
      fsType: ext4
    persistentVolumeReclaimPolicy: Retain
  ```

+ 관련 명령어

  + PV 생성 : `kubectl create -f [PV yaml 파일명].yaml`
  + PV 조회 : `kubectl get persistentvolume` / `kubectl get pv`

<br/>

## 퍼시스턴트 볼륨 클레임(PVC, Persistent Volume Claims)

```tex
▫️ PV와 pod를 연결하기 위한 리소스
```

<img src="https://user-images.githubusercontent.com/33214969/161439912-2f4340ed-6132-4f1a-9f9e-c597e60c7ac1.png" alt="Storage - PVC2.png" width="50%;" />

+ 특징

  + 사용자가 PVC를 생성하여 PV와 연결하여 pod에서 volume을 사용함
  + PVC 생성 시, 쿠버네티스틑 PVC 설정에 따라 PV를 바인딩(binding)함
  + 모든 PVC는 PV에 바인딩 됨 → 바인딩하는 과정에서 쿠버네티스는 PVC가 요청한 용량, 접근 모드, volume 모드, storage class 등의 속성에 따라 바인딩할 PV를 찾음 → 바인딩할 수 있는 volume이 여러 개인 경우, Label과 Selector를 이용하여 적절하게 volume을 바인딩하도록 설정할 수 있음
  + PVC가 요청한 용량 < PV에 설정된 용량인 경우 → 더 적합한 volume이 없을 경우에는 그냥 바인딩함 → PV의 용량이 남아도 다른 PVC는 사용 불가능함
  + PVC가 생성되었으나 바인딩할 PV가 없는 경우 → 사용가능한 PV가 생성될 때까지, PVC는 Pending 상태로 유지됨 → 사용할 수 있는 PV가 생성되면, 자동으로 바인딩됨
  + PVC 상태 - (생성 직후) Pending > (바인딩 후) Bound

+ PVC 생성 방법(yaml 파일)

  + persistentVolumeReclaimPolicy : PVC 삭제 시, PV 삭제 여부
    + Retain : (default) 관리자가 수동으로 PV를 삭제할 때까지, PV 유지 → 다른 PVC에서 재사용 불가
    + Delete : PVC 삭제 시, PV 자동 삭제
    + Recycle : 다른 PVC가 사용할 수 있도록 PV 데이터 정리

  ```yaml
  # pvc-definition.yaml
  apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    name: myclaim
  spec:
    accessModes:
      - ReadWriteOnce
    resources:    # resource 요청
      requests:
        storage: 500Mi
    persistentVolumeReclaimPolicy: Recycle
  ```

+ 관련 명령어

  + PVC 생성 : `kubectl create -f [PVC yaml 파일명].yaml`
  + PVC 조회 : `kubectl get persistentvolumeclaim` / `kubectl get pvc`
  + PVC 삭제 : `kubectl delete persistentvolumeclaim [PVC명]`

+ pod에서 PVC로 PV 지정하는 방법(yaml 파일)

  ```yaml
  apiVersion: v1
  kind: Pod
  metadata:
    name: mypod
  spec:
    containers:
    - name: myfrontend
      image: nginx
      volumeMounts:
      - mountPath: /opt
          name: data-volume
    volumes:    # volume 설정
    - name: data-volume
      persistentVolumeClaim:    # PVC 지정
        claimName: myclaim
  ```

<br/>

## 스토리지 클래스(Storage Class)

```tex
▫️ PV으로 확보한 Storage 종류를 정의하는 리소스
```

+ 특징

  + PVC 생성 시, Google Cloud와 같은 곳에 디스크를 생성 + 직접 PV 정의 파일을 생성해야 함 → provisioning volumes
  + storage class는 애플리케이션이 이를 요구할 때마다 volume이 자동으로 provision 될 수 있도록 도와줌 → 동적 프로비저닝(dynamic provisioning of volumes)
  + storage class를 생성하면 PV와 관련 storage가 자동으로 생성됨 → yaml 형식의 PV 정의 파일이 필요하지 X
  + PVC 정의 파일에 storage class의 이름을 지정하여 storage class를 설정함
  + storage class가 설정되면 provisioner를 사용하여 필요한 크기의 디스크를 프로비저닝한 PV를 생성하여 PVC에 바인딩함

+ yaml 파일

  + provisioner ex) AWS EBS, Azurefile, Azuredisk, CephFs, ...
  + parameters : 매개변수를 전달
    + type : 프로비저닝할 디스크 유형
    + replication-type : 복제 유형

  ```yaml
  apiVersion: storage.k8s.io/v1
  kind: StorageClass
  metadata:
    name: google-storage
  provisioner: kubernetes.io/gcp-pd
  parameter:
    type: pd-standard | pd-ssd
    replication-type: none | regional-pd
  ```

+ PVC에서 storage class 사용하기 + pod에 PVC 매핑(yaml 파일)

  + PVC

    ```yaml
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: myclaim
    spec:
      accessMode:
      - ReadWriteOnce
      storageClassName: google-storage  #storage class 설정
      resources:
        requests:
          storage: 500Mi
    ```

  + pod에서 PVC 매핑

    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: mypod
    spec:
      containers:
      - name: myfrontend
        image: nginx
        volumeMounts:
        - mountPath: /opt
            name: data-volume
      volumes:    # volume 설정
      - name: data-volume
        persistentVolumeClaim:    # PVC 지정
          claimName: myclaim
    ```

+ 관련 명령어

  + storage class 생성 : `kubectl create -f [sc yaml 파일명].yaml`
  + storage class 조회 : `kubectl get storageclass` / `kubectl get sc`
  + storage class 삭제 : `kubectl delete storageclass [SC명]`

<br/><br/>