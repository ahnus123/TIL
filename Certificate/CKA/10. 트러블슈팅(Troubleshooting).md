# 10. 트러블슈팅(Troubleshooting)

## Application Failure

### 1. Accessibility(접근성) 체크

+ 접근 가능 여부 체크 : `curl http://[web-service ip]:[node port]`

  <img src="https://user-images.githubusercontent.com/33214969/212490908-b6c3255a-14c7-42d8-a36e-fb5a6941f730.png" alt="Troubleshooting - Accessibility.png" width="70%;" />

### 2. Service 상태 체크

+ Service 상세 조회 : `kubectl describe service [service명]`

  <img src="https://user-images.githubusercontent.com/33214969/212490925-dcfb2ff3-af7c-4a14-9144-4aa3fb4a6c65.png" alt="Troubleshooting - Service.png" width="70%;" />

### 3. Pod 상태 체크

+ Pod 조회 : `kubectl get pod`

+ Pod 상세 조회 : `kubectl describe pod [pod명]`

+ Pod 로그 확인 : `kubectl logs [pod명]`

  <img src="https://user-images.githubusercontent.com/33214969/212490905-b4fa1b7f-6800-485a-bfa7-284fa744c5dd.png" alt="Troubleshooting -  Pod.png" width="70%;" />

<br/>

## Control Plane Failure

### 1. Node 상태 체크

+ Node 조회 : `kubectl get node`

+ Node 상세 조회 : `kubectl describe node [node명]`

  <img src="https://user-images.githubusercontent.com/33214969/212490920-1da8dfed-057b-44c3-97cc-a17cdbf5adb0.png" alt="Troubleshooting - Node.png" width="70%;" />

### 2. Controlplane Pod 체크

+ Controlplane Pod 조회 : `kubectl get pods -n kube-system`

  <img src="https://user-images.githubusercontent.com/33214969/212490911-b95ae77c-5900-48d8-8860-4080f90c6ac9.png" alt="Troubleshooting - Controlplane Pod.png" width="50%;" />

### 3. Controlplane Service 체크

+ Controlplane Service 조회 : `service kube-apiserver status` / `service kube-controller-manager status` / `service kube-scheduler status` / `service kubelet status` / `service kube-proxy status`

  <img src="https://user-images.githubusercontent.com/33214969/212490913-9c763af3-4d0b-48d9-b299-221b22f3e4e1.png" alt="Troubleshooting - Controlplane Service1.png" width="70%;" />

  <img src="https://user-images.githubusercontent.com/33214969/212490914-e177ba38-14cc-4fe4-85fb-16183a04d487.png" alt="Troubleshooting - Controlplane Service2.png" width="70%;" />

### 4. Service 로그 확인

+ kube-apiserver pod 로그 확인 : `kubectl logs kube-apiserver-master -n kube-system` / `sudo fournalctl -u kube-apiserver`

  <img src="https://user-images.githubusercontent.com/33214969/212490923-b024d564-15ea-4799-815b-b559e31505b6.png" alt="Troubleshooting - Service Log.png" width="70%;" />

<br/>

## Worker Node Failure

### 1. Node 상태 확인

+ Node 조회 : `kubectl get nodes`

+ Node 상세 조회 : `kubectl describe node [node명]`

+ Node 정렬 : `top` / `df -h`

  <img src="https://user-images.githubusercontent.com/33214969/212490921-54a78b9e-a299-4331-ab8f-9a283e5eebd2.png" alt="Troubleshooting - Node2.png" width="70%;" />

  <img src="https://user-images.githubusercontent.com/33214969/212490919-3c210a7d-bf04-4331-9b46-5ade8fd61ee5.png" alt="Troubleshooting - Node sort.png" width="70%;" />

### 2. Kubelet 상태 확인

+ Kubelet 상태 확인 : `service kubelet status` / `sudo journalctl -u kubelet`

+ Kubelet 시작 : `service kubelet start` / `systemctl start kubelet`

+ Kubelet 재시작 : `service kubelet restart`

  <img src="https://user-images.githubusercontent.com/33214969/212490917-e9ea9aea-1fe0-4a5c-8478-f94c7700ed61.png" alt="Troubleshooting - Kubelet.png" width="70%;" />

### 3. Certificate 확인

+ Certificate 확인 : `openssl x509 -in /var/lib/kubelet/[cert명].cert -text`

  <img src="https://user-images.githubusercontent.com/33214969/212490909-054edaad-4e4d-4303-9773-c3c73f916014.png" alt="Troubleshooting - Certificates.png" width="70%;" />

<br/>

## Networking

### 1. Network Plugin

+ `cni-bin-dir` : Kubelet이 시작할 때 해당 디렉토리에서 Plugin을 시도함
+ `network-plugin` : `cni-bin-dir`에서 사용할 Network Plugin
+ Network Plugin 종류
  + Weave Net
    + Install : `kubectl apply -f "<https://cloud.weave.works/k8s/net?k8s-version=$>(kubectl version | base64 | tr -d '\\n')"`<br/> → *https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/*
  + Flannel
    + Install : `kubectl apply -f <https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml`><br/> → Flannel은 쿠버네티스 network policy을 더이상 지원하지 않음
  + Calico
    + Install : `curl <https://docs.projectcalico.org/manifests/calico.yaml> -O` + `kubectl apply -f calico.yaml`

### 2. DNS

+ CoreDNS에 대한 리소스

  + service account → `coredns`
  + 클러스터 roles → `coredns`, `kube-dns`
  + 클러스터 rolebinding →  `coredns`, `kube-dns`
  + Deployment → `coredns`
  + Configmap → `coredns`
  + Service → `kube-dns`
  + Corefile plugin 위치 : `/etc/resolv.conf`

+ DNS 관련 Troubleshooting

  1. `coredns` Pod가 pending 상태인 경우 → network plugin 상태 확인

  2. `coredns`

      Pod가 CrashLoopBackOff or Error 상태인 경우

     1. docker를 최신 버전으로 업그레이드

     2. SELinux를 비활성화

     3. `coredns` Deployment를 수정 → `allowPrivilegeEscalation`을 true로 설정

     4. `coredns` Pod가 CrashLoopBackOff가 발생하는 또다른 원인 → `coredns`

         Pod가 loop를 감지하는 경우임

        + kubelet config yaml에 <실제 resolv config file 경로>를 추가 → 일반적으로 `/run/systemd/resolve/resolv.conf`가 resolv.conf의 위치이지만 다를 수도 있음
        + host 노드에서 로컬 DNS 캐시를 사용하지 않도록 설정 + `/etc/resolv.conf`를 원래 상태로 저장함

  3. `coredns` Pod와 `kube-dns` Service가 제대로 작동하는 경우 → `kube-dns` Service의 endpoint가 유효한지 확인<br/> → `kubectl -n kube-system get ep kube-dns`

### 3. Kube-Proxy

+ kubeadm으로 구성된 클러스터에서 kube-proxy를 daemonset으로 찾을 수 있음

+ kubeproxy는 각 서비스와 연결된 endpoint를 감시함. 클라이언트가 가상 IP를 사용하여 서비스에 연결하려고 할 때 kube proxy는 실제 pod로 트래픽을 보내는 역할을 함

+ kube proxy 컨테이너 내에서 kube proxy binary가 실행됨 → `kubectl describe ds kube-proxy -n kube-system`

  ```bash
  		Command:
        /usr/local/bin/kube-proxy
        --config=/var/lib/kube-proxy/config.conf
        --hostname-override=$(NODE_NAME)
  ```

  → `/var/lib/kube-proxy/config.conf`에서 config 파일을 가져오면 pod가 실행중인 node 이름으로 hostname을 재정의할 수 있음

+ Config file에서 재정의 가능한 항목 - clusterCIDR, kubeproxy mode, ipvs, iptables, bindadaddress, kube-config, ...

+ Kube-Proxy 관련 Troubleshooting

  1. kube-system namespace에서 kube-proxy pod가 실행중인지 확인함
  2. kube-proxy 로그를 확인함
  3. configmap이 올바르게 정의되어 있고 + kube-proxy binary를 실행하기 위한 config 파일이 올바른지 확인함
  4. kube-config는 configmap에 의해 정의됨
  5. kube-proxy가 컨테이너 안에서 실행중인지 확인 → `netstat -plan | grep kube-proxy`