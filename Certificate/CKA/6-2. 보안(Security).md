# 6-2. 보안(Security)

## Authorization

```tex
▫️ 사용자가 클러스터에 접근하여 할 수 있는 것을 정의함
```

+ 권한 부여 메커니즘

  ### Node authorization

  + kubelet은 apiserver에 접근하여 service, endpoint, node, pod의 정보를 읽거나 node 상태와 같은 정보를 apiserver에 전달함. 이러한 요청은 node authorizer의해 처리됨
  + 사용자 이름이 system:nodes 그룹에 속해야 함

  ### Attribute based authorization

  + 사용자 or 사용자 그룹을 권한 집합과 연결시키는 방법
  + json 형식의 정책 집합 파일을 생성하여 apiserver에 전달함. 변경/추가가 필요할 때마다 파일 수정 후 apiserver를 재시작해야 함.

  ### Role based authorization

  + 권한 집합으로 역할을 생성하여 사용자를 역할에 연결시키는 방법
  + 변경이 필요한 경우 역할을 수정하는 식으로 반영할 수 있음

  ### Webhook

  + 외부에서 인증을 관리하는 방법
  + 사용자 정보와 요청 정보를 이용해 인증 agent의 API를 호출하여 승인 여부를 결정함
  + API response에 기반하여 접근을 제어함

  ### AlwaysAllow

  + 모든 요청을 인증 없이 허용하는 방식

  ### AlwaysDeny

  + 모든 요청을 거부하는 방식

+ 권한 부여 메커니즘은 kube-apiserver에서 `--authorization-mode` 옵션을 사용하여 설정(default : AlwaysAllow)

  + 메커니즘은 쉼표로 구분하여 여러 메커니즘 사용하도록 설정 가능함 → 선언된 순서대로 동작함
  + 요청을 거부하면 다음 승인 메커니즘이 동작하며, 요청을 승인하면 다음 인증 메커니즘은 동작하지 않음

  + yaml 파일

    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      creationTimestamp: null
      name: kube-apiserver
      namespace: kube-system
    spec:
      containers:
      - command:
        - kube-apiserver
        - --authorization-mode=Node,RBAC    # 권한 부여 메커니즘 설정
        ...
    ```

<br/>

## RBAC(Role Based Access Controls)

### Role

+ 하나의 Role은 여러 규칙을 가질 수 있음
+ 하나의 Role은 접근을 허용할 apiGroup, resources, verbs(자원에 허용할 작업)으로 이루어져 있음

  + yaml 파일

    ```yaml
    apiVersion: rbac.authorization.k8s.io/v1
    kind: Role
    metadata:
      name: developer
    rules:
    - apiGroups: [""]
      resources: ["pods"]   # 권한을 부여할 자원
      verbs: ["list", "get", "create", "update", "delete"]   # 작업
    - apiGroups: [""]       # 다른 규칙
      resources: ["ConfigMap"]
      verbs: ["create"]
    ```

  + 관련 명령어

    + Role 생성 : `kubectl create -f [Role yaml 파일명].yaml` / `kubectl create role [role명] --namespace=[namespace명] --verb=[verb 리스트] --resource=[resource 리스트]`
    + Role 수정 : `kubectl edit role [role명] -n [namespace명]` → yaml 파일 수정
    + Role 목록 조회 : `kubectl get roles`
    + Role 상세 조회 : `kubectl describe role [Role명]`

### resourceNames

+ resource 중에서 특정 resource에 대한 접근만 허용할 때 사용함

  + yaml 파일

    ```yaml
    apiVersion: rbac.authorization.k8s.io/v1
    kind: Role
    metadata:
      name: developer
    rules:
    - apiGroups: [""]
      resources: ["pods"]     # 권한을 부여할 자원
      verbs: ["list", "get", "create", "update", "delete"]    # 작업
      resourceNames: ["blue", "orange"]
    ```

### RoleBinding

+ 사용자의 Role을 설정하는 객체
+ Role, RoleBinding 객체 → namespace 내에 생성됨
+ 특정 namespace 외의 자원에 대한 접근을 제한하고자 할 때에는 yaml 파일의 metadata 필드에 namespace를 지정해야 함

  + yaml 파일

    ```yaml
    apiVersion: rbac.authorization.k8s.io/v1
    kind: RoleBinding
    metadata:
       name: devuser-developer-binding
    subjects:    # 사용자 세부 정보 지정
    - kind: User
      name: dev-user
      apiGroup: rbac.authorization.k8s.io
    roleRef:    # 생성한 역할 세부 정보 제공
      kind: Role
      name: developer
      apiGroup: rbac.authorization.k8s.io
    ```

  + 관련 명령어

    + RoleBinding 목록 : `kubectl get rolebindings` / `kubectl create rolebindig [role명] --namespace=[namespace명] --role=[role명] --user=[user명]`
    + RoleBinding 상세 조회 : `kubectl describe rolebindings [rolebinding명]`

### kubectl auth can-i

+ 클러스터에 접속한 사용자가 클러스터 내에서 허용된 작업을 확인할 때 사용하는 명령어
  + 관련 명령어
    + 허용된 작업 확인 : `kubectl auth can-i [verbs(작업)] [resources]` ex) `kubectl auth can-i create deployments`
    + 관리자/특정 사용자의 권한 확인 : `kubectl auth can-i [verbs] [resources] --as [user]` / `kubectl auth can-i [verbs] [resources] --as [user] --namespace [namespace명]` ex) `kubectl auth can-i delete nodes --as dev-user`

<br/>

## Cluster Roles

### Namespace Scope Resource

+ Role, RoleBinding 객체 → namespace 내에 생성 & 해당 namespace 내 resource에 대한 접근만 제어함
+ namespace 내에 생성되는 자원 - Role, RoleBinding, Pod, ReplicaSet, Deployment, Job, Service, Secret, ...
+ Namespace Scope Resource 조회 : `kubectl api-resources --namespaced=true`

### Cluster Scope Resource

+ (특정 namespace에 한정되지 않는) cluster wide resource - Node, PV, ClusterRole, ClusterRoleBinding, CertificateSigningRequest, Namespace, ...
+ Cluster Scope Resource 조회 : `kubectl api-resources --namespaced=false`

### ClusterRole

+ 사용자에게 Cluster Scope Resource에 대한 접근 권한을 부여할 때 사용
  + ex) 클러스터 관리자에게 클러스터 노드 정보 조회/생성/삭제 or 스토리지 관리자에게 PV 생성
+ ClusterRole은 Namespace Scope Resource에 대해서도 생성할 수 있음
+ 모든 namespace에 대한 Resource 접근을 허용할 때 사용함
+ namespace에 해당하는 resource도 clusterrole을 사용할 수 있음 → 단, 모든 namespace에 대한 권한이 허용됨

  + yaml 파일

    ```yaml
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      name: cluster-administrator
    rules:
    - apiGroups: [""]
      resources: ["nodes"]
      verbs: ["list", "get", "create", "delete"]
    ```

  + 관련 명령어

    + ClusterRole 생성 : `kubectl create -f [ClusterRole yaml 파일명].yaml` / `kubectl create clusterrole [clusterrole명] --verb=[verb 리스트] --resource=[resource 리스트]`
    + ClusterRole 수정 : `kubectl edit clusterrole [clusterrole명]` → yaml 파일 수정
    + ClusterRole 목록 조회 : `kubectl get clusterroles`
    + ClusterRole 상세 조회 : `kubectl describe clusterrole [ClusterRole명]`

### ClusterRoleBinding

+ RoleBinding과 마찬가지로 ClusterRole과 사용자를 연결하는 객체

  + yaml 파일

    ```yaml
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      name: cluster-admin-role-binding
    subjects:    # 사용자 정보
    - kind: User
      name: cluster-admin
      apiGroup: rbac.authorization.k8s.io/v1
    roleRef:    # ClusterRole 정보
      kind: ClusterRole
      name: cluster-administrator
      apiGroup: rbac.authorization.k8s.io/v1
    ```

  + 관련 명령어

    + ClusterRoleBinding 목록 : `kubectl get clusterrolebindings` / `kubectl create clusterrolebindig [role명] --clusterrole=[clusterrole명] --user=[user명]`
    + ClusterRoleBinding 상세 조회 : `kubectl describe clusterrolebindings [clusterrolebinding명]`

<br/>

## Service Account

```tex
▫️ 애플리케이션이 쿠버네티스 클러스터와 상호작용하기 위해 사용되는 계정
```

+ Service account를 통해 요청이 인증됨
+ ex) prometheus와 같은 모니터링 앱이 metrics를 가져오기 위해 쿠버네티스 api에 요청할 때 사용됨
+ Service Account가 생성되면 → token이 자동으로 생성됨
  + 이 tocken은 외부 애플리케이션이 쿠버네티스 api에 인증하는 데 사용됨 → secret object로 생성됨
+ 각 namespace는 Default Service Account를 갖게 됨
+ pod 생성 시 → Default Service Account와 token이 자동으로 pod에 volume mount로 마운트됨

  + 자동 마운트 방지(yaml 파일)

    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: my-kubernetes-dashboard
    spec:
      containers:
        - name: my-kubernetes-dashboard
          image: my-kubernetes-dashboard
      automountServiceAccountToken: false    # 자동 마운드 방지
    ```

+ pod 생성 시 다른 Service Account를 사용하려면 → `spec.serviceAccountName`에 지정하면 됨
  + 존재하는 pod는 변경 불가 → 변경 시, pod 삭제 후 재생성해야 함
  + deployment는 변경 가능 → rollout됨

  + yaml 파일

    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: my-kubernetes-dashboard
    spec:
      containers:
        - name: my-kubernetes-dashboard
          image: my-kubernetes-dashboard
      serviceAccountName: dashboard-sa    # Service Account 설정
    ```

+ 관련 명령어

  + Service Account 생성 : `kubectl create serviceaccount [serviceaccount명]`
  + Service Account 조회 : `kubectl get serviceaccounts`
  + Service Account 상세 조회 : `kubectl describe serviceaccount [service account명]`
  + token 확인 : `kubectl exec -it [pod명] cat /var/run/secrets/kubernetes.io/serviceaacount/token`
  + 자동 마운트 방지 : (설정) `spec.automountServiceAccountToken=false`

<br/>

## [Image Security](https://www.notion.so/Security-aef36bbc7d87463db2b035133dcd4da9)

<img src="https://user-images.githubusercontent.com/33214969/161428368-1e8adf91-7b5d-4feb-a9b9-67783232636b.png" alt="Security - image security.png" width="50%;" />

+ 쿠버네티스로 image를 받아오기 위한 credential을 어떻게 넘기는지?

  1. credential을 가진 docker-registry 타입의 secret을 생성 : `kubectl create secret docker-registry [secret명] --docker-server=[registry server] --docker-username=[user명] --docker-password=[password] --docker-email=[email]`

  2. pod 생성 시, imagePullSecret 지정 → 생성한 secret 지정

     ```yaml
     apiVersion: v1
     kind: Pod
     metadata:
       name: private-reg
     spec:
       containers:
       - name: private-reg-container
         image: [private image명]
       imagePullSecrets:
       - name: [secret명]
     ```

<br/>

## Security Contexts

+ 도커 컨테이너에 프로세스 실행 user와 capabilities를 설정할 수 있는 것과 같이 쿠버네티스도 동일하게 설정이 가능함
+ 쿠버네티스 컨테이너는 pod에 캡슐화 되어 있음 → 컨테이너 레벨 or pod 레벨에서 설정 가능함

  + pod 레벨

    + pod  내 모든 컨테이너에 설정을 적용함
    + yaml 파일에서 securityContext 옵션을 사용하여 프로세스 실행 user를 지정할 수 있음

    + yaml 파일

      ```yaml
      apiVersion: v1
      kind: Pod
      metadata:
        name: web-pod
      spec:
        securityContext:    # pod 레벨에서 user 지정
          runAsUser: 1000
        containers:
        - name: ubuntu
          image: ubuntu
          command: ["sleep", "3600"]
      ```

  + 컨테이너 레벨

    + 컨테이너 레벨에서 설정 → 기존 pod 레벨에서 설정되어 있는 경우 컨테이너 설정으로 재정의함
    + securityContext 옵션을 containers 항목 아래로 내리면 → 컨테이너 수준에서 설정이 가능함
    + `capabilities` 옵션 → 쿠버네티스 컨테이너에 capabilities 지정 가능함

    + yaml 파일

      ```yaml
      apiVersion: v1
      kind: Pod
      metadata:
        name: web-pod
      spec:
        containers:
        - name: ubuntu
          image: ubuntu
          command: ["sleep", "3600"]
          securityContext:    # 컨테이너 레벨에서 user 지정
            runAsUser: 1000
            capabilities:
              add: ["MAC_ADMIN"]
      ```

  + 관련 명령어

    + user 확인 : `kubectl exec [pod명] -- whoami`

<br/>

## Network Policy

+ Ingress : 서버 입장에서 들어오는 트래픽
+ Egress : 서버 입장에서 내보내는 트래픽

  <img src="https://user-images.githubusercontent.com/33214969/161428369-891cc65b-e299-4e4f-9f51-fc940590bbf0.png" alt="Security - Ingress:Egress.png" width="50%;" />

+ All allow : 모든 pod에서 다른 pod or service로 트래픽을 허용 → 쿠버네티스가 기본적으로 구성하는 규칙으로, 쿠버네티스는 어떤 솔루션을 구현하든 추가 설정 없이 pod 간 통신이 가능함을 전제로 함

### Network Policy

```tex
▫️ pod 그룹에 대해 서로 간 or 외부 네트워크 endpoint와의 통신 여부를 결정하는 정책
```

<img src="https://user-images.githubusercontent.com/33214969/161428374-07afb407-f6f6-4972-a8ba-2a57570937fa.png" alt="Security - Networking Policy.png" width="30%;" />

<img src="https://user-images.githubusercontent.com/33214969/161428376-ef1ddc8e-efc4-43f0-b3fb-104b8ed23020.png" alt="Security - Networking Policy2.png" width="20%;" />

+ Network Policy를 생성하여 pod에 적용 → 적용된 pod에서는 규칙에 해당하는 트래픽만 허용 + 다른 트래픽은 차단
+ 네트워크 보안을 구현해야할 때 사용됨 ex) 웹 서버가 동작하는 pod에서 DB가 동작하는 pod로의 직접 통신을 제한
+ Label과 Selector를 이용하여 pod에 적용함
+ Network Policy를 지원하는 네트워크 솔루션 : kube-router, Cliaco, Romana, Weave-net<br/> * Flannel은 지원 X

+ yaml 파일

  ```yaml
  apiVersion: networking.k8s.io/v1
  kind: NetworkPolicy
  metadata:
    name: db-policy
  spec:
    podSelector:
      matchLabels:
        role: db
    policyTypes:
    - Ingress
    ingress:    # Ingree 규칙
    -	from:
      - podSelector:  # Policy가 적용되는 pod 그룹 선택. 빈 값 -> namepace의 모든 pod
          matchLabels:
            name: api-pod
      ports:
      - protocol: TCP
        port: 3306
  ```

+ 관련 명령어

  + Network Policy 조회 : `kubectl get networkpolicy`
  + Network Policy 상세 조회 : `kubectl describe networkpolicy [network policy명]`

### Developing Network Policy

+ 클러스터 내의 Label은 같지만 namespace가 다른 pod가 여러 개 있는 경우 → 모든 namespace에서 Label이 일치하는 모든 pod의 연결이 허용됨

  + yaml 파일

    <img src="https://user-images.githubusercontent.com/33214969/161428377-f129b384-a112-46f6-bc9f-55d9ff6d1e74.png" alt="Security - Networking Policy3.png" width="50%;" />

    → 다른 namespace의 “API Pod”의 연결을 허용

    ```yaml
    apiVersion: networking.k8s.io/v1
    kind: NetworkPolicy
    metadata:
      name: db-policy
    spec:
      podSelector:
        matchLabels:
          role: db
      policyTypes:
      - Ingress
      ingress:    # Ingree 규칙
      -	from:     # Ingress 허용 트래픽 소스
        - podSelector:
            matchLabels:
              name: api-pod
        ports:
        - protocol: TCP
          port: 3306
    ```

+ 특정 namespace의 pod만 허용하고 싶은 경우 → `namespaceSelector` 사용

  + yaml 파일

    <img src="https://user-images.githubusercontent.com/33214969/161428386-c480b020-6b36-4fcf-8635-c1d57e1580a3.png" alt="Security - Networking Policy8.png" width="50%;" />

    → “prod” namespace의 “API Pod”의 연결을 허용

    ```yaml
    apiVersion: networking.k8s.io/v1
    kind: NetworkPolicy
    metadata:
      name: db-policy
    spec:
      podSelector:
        matchLabels:
          role: db
      policyTypes:
      - Ingress
      ingress:    # Ingree 규칙
      -	from:     # Ingress 허용 트래픽 소스
        - podSelector:
            matchLabels:
              name: api-pod
          namespaceSelector:    # 해당 namespace만 허용
            matchLabels:
              name: prod
        ports:
        - protocol: TCP
          port: 3306
    ```

+ podSelector가 없고 namespaceSelector만 있는 경우 → 설정된 namespace 내의 모든 pod와의 연결을 허용 + 그 외 pod는 허용 X

  + yaml 파일

    <img src="https://user-images.githubusercontent.com/33214969/161428387-31de6aa4-713d-4ed2-aad1-127836ad4ecf.png" alt="Security - Networking Policy9.png" width="50%;" />

    → “prod” namespace의 “API Pod”의 연결을 허용

    ```yaml
    apiVersion: networking.k8s.io/v1
    kind: NetworkPolicy
    metadata:
      name: db-policy
    spec:
      podSelector:
        matchLabels:
          role: db
      policyTypes:
      - Ingress
      ingress:    # Ingree 규칙
      -	from:     # Ingress 허용 트래픽 소스
          namespaceSelector:
            matchLabels:
              name: prod
        ports:
        - protocol: TCP
          port: 3306
    ```

+ 클러스터 외부에서 pod에 연결하고 싶은 경우 → 클러스터 내에 속하지 않기 때문에 selector가 동작 X → 특정 IP의 트래픽을 허용하도록 ipBlock을 사용

  + yaml 파일

    <img src="https://user-images.githubusercontent.com/33214969/161428382-3b4c32d9-0e3c-48ea-9250-7f5706f0767b.png" alt="Security - Networking Policy5.png" width="50%;" />

    → 클러스터 외부의 192.168.5.10 ip의 연결을 허용

    ```yaml
    apiVersion: networking.k8s.io/v1
    kind: NetworkPolicy
    metadata:
      name: db-policy
    spec:
      podSelector:
        matchLabels:
          role: db
      policyTypes:
      - Ingress
      ingress:    # Ingree 규칙
      -	from:     # Ingress 허용 트래픽 소스
        - podSelector:
            matchLabels:
              name: api-pod
          namespaceSelector:
            matchLabels:
              name: prod
        - ipBlock:    # 해당 ip의 연결을 허용
            cidr: 192.168.5.10/32
        ports:
        - protocol: TCP
          port: 3306
    ```

  + `from` 항목 아래의 `-`로 묶인 규칙 → AND로 적용 / `from` 항목 아래 각각의 `-` 규칙 → OR로 적용

+ yaml 파일

  ```yaml
  apiVersion: networking.k8s.io/v1
  kind: NetworkPolicy
  metadata:
    name: db-policy
  spec:
    podSelector:
      matchLabels:
        role: db
    policyTypes:
    - Ingress
    - Egress
    ingress:    # Ingree 규칙
    - from:     # Ingress 허용 트래픽 소스
      - podSelector:  # Policy가 적용되는 pod 그룹 선택. 빈 값 -> namespace의 모든 pod
          matchLabels:
            name: api-pod
      ports:
      - protocol: TCP
        port: 3306
    egress:     # Egress 규칙
    - to:       # Egress 허용 트래픽 소스
      - ipBlock:
          cidr: 192.168.5.10/32    # pod to 192.168.5.10 ip로 연결 허용
      ports:
      - protocol: TCP
        port: 3306
  ```

+ CKA 문제 예시

  Create a network policy to allow traffic from the `Internal` application only to the `payroll-service` and `db-service`.
  Use the spec given on the below. You might want to enable ingress traffic to the pod to test your rules in the UI.
  + Policy Name: internal-policy
  + Policy Type: Egress
  + Egress Allow: payroll
  + Payroll Port: 8080
  + Egress Allow: mysql
  + MySQL Port: 3306

    ```yaml
    apiVersion: networking.k8s.io/v1
    kind: NetworkPolicy
    metadata:
      name: internal-policy
    spec:
      podSelector:
        matchLabels:
          name: internal
      policyTypes:
      - Egress
      egress:
      - to:
        - podSelector:
            matchLabels:
              name: mysql
        ports:
        - protocol: TCP
          port: 3306
      - to:
        - podSelector:
            matchLabels:
              name: payroll
        ports:
        - protocol: TCP
          port: 8080
    ```

<br/><br/>

[참고] https://passwd.tistory.com/105?category=1210080<br/>
